{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network train and test that predicts the non linear power spectrum using the cosmopower code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = 'gpu:0' if tf.config.list_physical_devices('GPU') else 'cpu'\n",
    "print('using', device, 'device \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "training_parameters = np.load('./params.npz')\n",
    "# Training spectrum\n",
    "training_spectrum = np.load('./spectra.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# See if there is inf or nan values in the files\n",
    "def contains_inf_or_nan(arr):\n",
    "    for value in arr:\n",
    "        if math.isinf(value) or math.isnan(value):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "arrays = training_spectrum['features']\n",
    "\n",
    "for i, arr in enumerate(arrays):\n",
    "    if contains_inf_or_nan(arr):\n",
    "        print(f\"Array {i} contains inf or nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the parameters that are being used\n",
    "model_parameters = ['Omega_b', \n",
    "                    'Omega_c', \n",
    "                    'A_s_1e9', \n",
    "                    'n_s', \n",
    "                    'xi',\n",
    "                    'h',\n",
    "                    'z',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavenumber values\n",
    "k_values = training_spectrum['modes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cosmopower import cosmopower_NN\n",
    "\n",
    "# Instantiate NN class\n",
    "cp_nn = cosmopower_NN(parameters=model_parameters, \n",
    "                      modes=k_values, \n",
    "                      n_hidden = [512, 512, 512, 512], # 4 hidden layers, each with 512 nodes\n",
    "                      verbose=True, # useful to understand the different steps in initialisation and training\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "with tf.device(device):\n",
    "    \n",
    "    cp_nn.train(training_parameters=training_parameters,\n",
    "                training_features=training_spectrum['features'],\n",
    "                filename_saved_model='trained_model',\n",
    "                validation_split=0.1, # Proportion of the training data to be used for validation. In this case, 10% of the data will be used for validation\n",
    "                learning_rates=[1e-2, 1e-3, 1e-4, 1e-5, 1e-6], # Controls how much the model's weights are adjusted with respect to the loss gradient during each update\n",
    "                batch_sizes=[1024, 1024, 1024, 1024, 1024], # Number of samples that will be passed through the network at once before updating the model's parameters\n",
    "                gradient_accumulation_steps = [1, 1, 1, 1, 1], # Accumulating gradients over multiple mini-batches before updating the model weights\n",
    "                patience_values = [200,200,200,200,200], # Prevent overfitting by halting the training process if the model's performance on a validation set does not improve after a specified number of epochs\n",
    "                max_epochs = [1000,1000,1000,1000,1000], # Total number of complete passes through the entire training dataset\n",
    "                )\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
